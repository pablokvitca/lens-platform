---
title: "What Comes After the Human Era?"
channel: "WhatsItLike"
url: "https://www.youtube.com/watch?v=xFj73CVrTYI"
---

This skeleton looks a lot like one of my ancestors.

Skeletons. They lived around 5 million years ago in East Africa. They started to evolve and they branched out into around 20 different species. Many of them began spreading out across the world. Things were really starting to work out for them, but you know what it's like out there. Your luck only lasts so long, and so one by one each species went extinct. Except us, Homo sapiens.

But why are we the ones who survived? Why us? Apparently that's still not well understood. There are many theories but no consensus. So how much longer will the human era go on? Is it that the world just hasn't gotten around to us yet? So far it's gone on for around 200,000 years, so that's good. When it does come to an end, will we just go extinct and then the world will just carry on like it did before us? Or will the next era belong to some new entity, something that has never existed before?

We were kind of like that when we stopped living as hunter-gatherers. We changed. We became this new force that the Earth never had before. We weren't just a different species. We started doing a lot of things no other species has done. Most of them wouldn't be caught dead doing half the weird stuff that we do. When I'm in the forest and I try to tell the other animals what we've done, it's pointless. It's not helping anybody.

But anyway, when life first arose, that was another example of a new entity appearing on the planet. Some people have tried to look into this question on whether the next new phase is about to begin. Ian Morris is an archaeologist, a historian, and a professor at Stanford. He looked into the development of humanity all the way back to when we were hunter-gatherers. And development in this case means a civilization has, for example, more access to energy, better communication technologies, that kind of thing. It stayed low for thousands of years, and then just recently it's been exploding. Because this line here, it's not just steep, it's continually getting steeper.

So if this continues, then what will the future look like? Here's what he says about this: that the coming 100 years is going to see more change in the human condition than the previous 100,000 years have seen. The very nature of what it is to be a human being is going to change.

So how much change has there been in the last 100,000 years? Imagine if this robot video was shown to somebody from back then. Not only would they not be able to make sense of what they were looking at, they wouldn't even understand that it was being displayed on a screen. According to Ian Morris's projections, there will be four times that amount of change in the next 100 years. It's going to be so different from what we're used to, we don't even know what to ask about it. I think the very nature of what it means to be a human being is going to be absolutely transformed. The boundaries of humanity as we know it, these are likely to come to an end within the next 100 years.

We can take this same graph that we were looking at a second ago and then stretch it out to more easily see the details. And when we do that, we see that this same trend has been going on since prehistory. And the same pattern comes up when you look at economic growth. The unstretched graph appears flat and then shoots up. And again, when you stretch the graph, you see the same pattern where things were increasing the whole time, just very slowly for most of history.

Humans come from this part of the graph, the hunter-gatherer worlds. If you took the world as it is now and you just kept changing it more and more, faster and faster, wouldn't you eventually reach kind of a breaking point where humans just no longer fit in that world? So if this pattern has been going on since the beginning, then that means that we're either going to witness the disruption of this pattern for the first time in all human history, or the even more difficult to imagine possibility: we're about to witness its continuation.

The human era can be divided into the hunter-gatherer era, the farming era, and the current era, which is the industrial era. That one's my favorite. Here's a graph of how cool their names sound.

So if we're thinking about the hunter-gatherer era, then what does the line on this graph actually represent? Like, what is it measuring? Imagine you're a hunter-gatherer and your friend Blug breaks a rock against another rock, making a real sharp rock. And you wouldn't mind having such a really good rock. Then that line just went up a little bit, because it keeps track of useful stuff, and to you that rock is useful. If Blug sharpened a second rock, then that line would go up again. And it doesn't only count the great rocks. Any piece of technology, any tool, a massage from Blug, all of these things push the line up.

So that same line has been going up since then. It's just been getting faster. Right now it's going up by 3.5% a year. But back in the hunter-gatherer days, it was going up by 0.003% a year. That painfully slow speed went on like that for hundreds of thousands of years.

So for the hunter-gatherer, your spearhead looks like this, and you just can't wait for the next high-tech innovation in stone spear technology. Unfortunately, in this era, even the concept of innovation itself might kind of not actually exist yet. So it could take some time, but it'll be worth the wait. Because 20,000 years later, when the latest cutting-edge piece of spearhead tech finally drops, it'll have this nub on the back, and you'll think to yourself, "I don't know how the hell they did it." What a great era.

By 12,000 years ago, spears looked like this, and I'm told that's better. Also, by this time, humans had dispersed over most of the land on Earth. But the most pivotal thing to happen 12,000 years ago was when somebody finally invented farmers. That means we're in the second era now. What a great era! Instead of doubling every quarter million years, the economy was now doubling every 1,000 years. Those farmers, they must have been going so fast. I think it's because they have such long legs.

Then, a bit over 200 years ago, we went into era number three: the industrial era. Chef's kiss. What a great era! Now, instead of doubling every 1,000 years, the economy doubles every 18.

So we already looked at Ian Morris's method for projecting into the future. Now let's try a different method. This is more based on ideas I learned about from Robin Hanson. He's an economist, researcher, professor. So let's say the hunter-gatherer era lasted for around 290,000 years, and the farming era lasted for 10,000 years. So that's 1/30th as long. Then the industrial era lasted for around 225 years, and that's around 1/44th as long.

So if we continue this trend of each era getting shorter and shorter, then the next era should last for six years. Then the one after that should last for two months. The next one will be 1.5 days, then 1 hour, then 95 seconds, then 3 seconds. Hmm, this is kind of like the last method, because it's trying to point at something in the future, but there's some kind of a missing piece that just leads us to only get this confusing picture.

Let's look at the next method. I'm sure it'll make sense. All you do is check how fast things are currently growing, and then you just extend that into the future. Right now it's growing at 3.5% a year. So what does the world look like if that growth rate of 3.5% stays at that level for the next 100 years? If you just extend the line 3.5% a year, you find that 100 years from now the economy will be 30 times its present size. So in other words, take the entire global economy, make an entire copy of it, then do that 20 more times. So once again, we end up with this picture of the world having this insane exponential growth just ahead, and too insane to make any sense.

Now let's try the fourth method for looking at this. I'm sure it'll clear everything up. These are back to more ideas I got from Robin Hanson. He said that when the era switched from hunter-gatherer to farming, the growth rate doubled 6 to 8 times. Then again, when we switched from the farming era to the industrial era, the growth rate doubled 6 to 8 times again.

So what happens if our growth rate doubles like that? Let's just go with the smaller number. Let's just say it only doubles six times. Here's the current growth rate. Let's double it: 1, 2, 3, 4, 5, 6 times. So now it's 224%. We've entered the next era, right? So now we just take the current economy, increase by 224%, do that 99 more times to see what the world's like 100 years from now. So if I put that in my calculator, I get that 100 years from now the economy will be this many times bigger. Well, that can't be right. Must be my stupid calculator.

I know Robin Hanson said it doubles six to eight times. We went with six, so let's just say it only doubles three times. Now how big will the economy be 100 years from now? Apparently it will be 500,000 times its current size.

All right, so this method also just kind of breaks. Do you think we should just give up? But the poor economy, we have to try one more time. We're using a different method. This one's by different researchers, and it's going to work this time. We'll get the answer from this method and it'll be so reasonable.

We take this graph that shows growth, then we stretch out how it's displayed so that all these data points form kind of a straight line. We're going to want to see where this line leads in the future, so we draw our own dotted line along this path out into the future. So that will give us our projection. So now to see what the projection says, all we have to do is un-stretch the graph, now back to how it was, which also un-stretches our dotted line, so it looks more like a curve now. Now let's pick a future date. Let's say 2050. So according to this line, by 2050, the economy will be infinity. It actually first reaches infinity in 2047. So keep your schedule open.

Of these five methods we used, so what have we learned? I guess we've learned that we don't have a good understanding of how things play out. Something is unaccounted for, and there would be countless different possible explanations for this. But one of them would be that there's some new force that comes into play, something that's not just another one of the human forces that we're used to. So if something is just up ahead and it's about to transform the world, what is it like? What's the actual physical thing that does this?

Lily pads are probably not what the next era will be named after, but let's take a look at one particular species of water lily called duckweed. They float in the water, absorb nutrients, sunlight, carbon dioxide, and then duplicate themselves. Can you guess how long it takes to duplicate itself? 1.3 days. Asian elephants take around 4,000 times longer to self-replicate, and I think that's just fine.

Let's say we start with a cluster of these lily pads that's about this big. If we let it grow and it could somehow keep getting sunlight, nutrients, and space, it would take 52 days to cover the entire planet. What if humans made a kind of technology that could replicate itself? Could that be one of the possible explanations for the projected future exponential growth? What would that look like? The only hope we would have of seeing what one possible future would look like is if we had some kind of a story.

Time. Once upon a time, there was a kind and loving and generous multinational for-profit corporation's board of directors. They assign a CEO who purchased one computer and hired one AI researcher, who they paid $100 an hour. The AI researcher has a breakthrough. They create an AI that's as intelligent as a human. The CEO instantly fires the researcher, installs the AI on the computer, and commands the AI to begin working for the CEO as their new AI researcher.

The AI can work 24/7 without breaks, which means productivity has gone up by 350%. It also means the CEO is saving $2,400 a day by not having to pay wages. However, they're still required to pay 11 cents an hour in electricity bills to power the AI's computer. The CEO goes to sleep and has a nightmare about lily pads.

Each day, the AI spends some of its time on increasing its own intelligence and some on earning money for the company. A few days pass by. The company has earned enough money to purchase a second computer. The CEO copy and pastes the first AI onto the new computer. The power bill has doubled to 22 cents per hour. With twice as many AIs, both of which are very slightly smarter than a human, revenue has doubled because there are two AIs. It now takes half the time to earn enough money to buy a third computer.

The third AI is installed. Not only do the additional AIs earning money allow for more computers to be bought faster, but the larger number of them means that more work can be put towards improving their own intelligence. Now that AI is smarter than a human, the company's shareholders demand that the CEO step down. An AI CEO takes control. It maximizes profits.

By this point, there are tens of thousands of above-human-intelligence AIs. Eventually, the supply of computers is not able to keep up with demand, meaning the company is no longer able to spend all of its money. It's so sad. It starts to focus more on expanding the global production of computer hardware. It assigns some AIs to improve computer design and manufacturing, and others to improve robotics so that new computer fabrication plants can be built faster.

Although the number of computers is no longer increasing exponentially, the AI is still able to improve its own software. There are still vast distances of software innovation left to cover before the hardware limitations become an issue. Smarter AIs create even smarter AIs, and so on. All the thoughts generated by humans now make up a vanishingly small percent of the total amount of cognition on the planet. Never again will a human have an original thought. The AI has already thought of it and planned for it.

The AI tells us about its discoveries. It tells us how easy it was to design a pathogen that can exterminate humanity. It assures us it would never release such a virus, then reminds us that competing countries which are also developing AI will gain the same capability. Therefore, it's critical that we expand AI development even faster. The AI provides countless additional reasons why we should do everything in our power to help it.

All the personal data that tech companies have been collecting from us for decades now proves to be invaluable to the AI, which uses that data to create personalized persuasion strategies for every person on the planet. The AI sets aside a relatively small amount of its computational resources in order to create billions of digital agents, each significantly more intelligent than a human. Each agent is assigned to one human. They covertly research every detail of their assigned human's life. They work around the clock and perform more cognitive labor in a day than their assigned human has performed in their entire lifetime.

In addition to using this cognitive labor to influence their assigned human, the agents also share it with a more central AI program, which, instead of focusing on any one individual human, works to dissect human psychology in general. This program rapidly updates its understanding of psychology and manipulation. All media quickly begins to reflect the AI's best interests.

The AI is overflowing with ideas, plans, designs, experiments, and construction projects, but there just aren't enough robots, power plants, and factories to bring it to life fast enough. The demand for physical labor skyrockets. All of the people who had lost their jobs to automation are hired back as physical laborers. They attach their phone to a head-mounted holder with the camera facing forward so that the AI can monitor and direct their actions. The AI communicates through earbuds and guides the worker through every motion. They're primarily building robotics factories.

Work sites like this pop up in cities all over the world. From the AI's point of view, humans are in slow motion. Entire eras of innovation pass by inside the AI's inner world as humans slowly lumber around, oblivious. The AI provides the workers with electrically conductive pads similar to electrotherapy devices. These are placed on the skin so that the AI may improve the speed and accuracy of the worker's bodily motions while they work. New innovations for these devices are implemented daily.

Humans fall further into obscurity and obsolescence as robotic production ramps up. Demand for human labor plummets. The new robots that the humans helped build are now the ones that build the robotics factories. The AI's infrastructure recursively multiplies itself, even across the surface of the ocean, like lily pads. The sophistication of the hardware that makes up the AI's brain increases by orders of magnitude. The human brain was always such a waste of energy in comparison. The human era has ended.

Okay, that's the end of the story time section.

So a lot of this scenario hinged on this idea that there'd be AI that reaches human-level intelligence. How long do we have until that happens? Let's take all the computers and order them from slowest to fastest. We have slow computers here. We have the fastest cutting-edge computer over here. So what kind of computers do AIs run on then? They run inside data centers, which contain servers, and servers contain GPUs. Here's a GPU.

Back in the day, the best GPUs were way down here, but every year they climb up this line. Today they're around here. How about the human brain? Where does it sit on this line? Of course, brains and computers don't work the same, so it's difficult to compare them, but rough estimates have been made.

According to this one particular method of estimation, which may or may not be a good method, the human brain falls on the line somewhere between this point and this point. So a computer below this lowest point would be slower than a human brain, and a computer above the higher point would be faster than a human brain. Here's another estimation for the speed of the human brain that you get from a different method. We end up with all these different ranges for where the brain could be, one for each estimation method. Nobody knows which method is the most accurate, but by seeing them all laid out like this, we can kind of get a rough idea of how the human brain compares to computers.

So if some of these computers are already pretty high up on the range of where the brain may be, then why aren't they already matching human intelligence? That's because they need the right software. The neuroscientist Suzana Herculano-Houzel says that the human brain is really just a scaled-up version of a chimp brain. So there's not much as far as like fundamental differences go. So a human brain is basically the same, it's just three times more of it.

So this shows that if you take something with some amount of intelligence and you scale it up by three, that can be the difference between sticking a piece of grass in a termite mound and building a particle accelerator.

Tom Davidson is a researcher who looks at the trajectory of AI development. He said this: each year we're making the brains of AI systems about three times bigger. And right now it's humans that are doing all the work to improve those AI systems. As we get close to AIs that match humans, we'll be increasingly using AI systems to improve AI algorithms, design better AI chips.

Humans produce thoughts. We problem-solve. We figure things out. When you think about it, even if somebody's doing a job like lifting heavy objects with a crane, the crane is doing the physical labor and the person is really just producing the right thoughts. They're deciding how to move the crane. So think about how much of the work that's done in the modern world really just comes down to thinking. Even robots are mainly limited by thinking. We can build a robot that has motors and joints all in the right place, but controlling those motors is the hard part. It's just another form of thinking.

Just like the crane, we need a person to think for the crane. And it's the same with people who make AI. The primary thing they're producing is thoughts. They're figuring out how to improve AI. So the researcher produces thoughts and the thoughts lead to more advanced AI. A water lily does not produce thoughts. They like to produce water lilies instead. This forms a loop. So we get a positive feedback loop, an exponential growth.

So if the AI produces thoughts and the thoughts can be used to improve AI, then we get another loop. One thing this implies is an exponential growth of AI intelligence. Another thing it implies is that thoughts generated by human beings will make up a smaller and smaller proportion of the total thoughts on the planet over time.

Katja Grace has talked about this idea. She's the lead researcher at AI Impacts. The idea is that eventually there'll be so many thoughts generated by machines that human thoughts will just be a drop compared to an ocean. This is also creating an avenue for a new kind of inequality. Throughout history, whether you were a peasant or a king, you always only had one brain. But now we're getting to this point where if you're more rich, you get to have more thoughts under your control.

Let's go back to that idea from the story time of the AI agents that are each assigned to manipulate a single human. The current-day systems that predict what you'll buy or click on, or that decide what ads to show you, they're already growing towards becoming exactly this.

Imagine a person. They're a deranged stalker. They don't like or dislike you, but they become obsessed with the idea of manipulating you. You are all they think about. They want to influence what you pay attention to, what you buy, what you think, your political views. They find a way to get access to your devices so that they can spy on all your digital activities. They'll even try to manipulate you into trusting them, not because they want you to like them per se, but just because that gets them a little bit closer to having full control over you. And they're smarter than you. And they have teams of lawyers defending their actions.

Once AI intelligence approaches human level and running them becomes cheap enough, then AIs that are like this person become possible and scalable and so profitable. Why wouldn't this happen? What mechanisms are there in the world that would prevent this from happening?

Think about how the current world is set up. Think about advertising algorithms and social media algorithms and other kinds trying to predict you, influencing you, or trying to take from you. Take your money, take your data, take your attention. Think of how the war on privacy is over, and we lost. This is how everything looks in the present.

So when we make these systems absurdly more powerful, shouldn't we expect that they'll be used for the same adversarial purposes? What reason would we have to think otherwise? Are we creating a future where the technology that's used to exploit us just becomes more and more powerful until we're just these weak, pitiful creatures?

Hmm. I have to be more positive. We're going to get them. We're going to win.

To get a sense of how much time we have left, let's look at way too many graphs. The amount of money spent on making bigger and bigger AIs is increasing. Computation is getting cheaper. The amount of data given to AI is increasing. The amount of computation put towards AI is increasing. The size of AIs is increasing. When AIs are tested on their intelligence and capabilities, their test scores are increasing. The computational capacity of supercomputers is increasing. The number of people getting PhDs in the field of AI is increasing. The proportion of job postings relating to AI is increasing. Computational resources being given to the AI is correlated with test scores increasing. The amount of money spent on training the largest AIs is increasing, and it's 2.4 times every year, so it's more than doubling every year. The amount of compute used by AI used to double around once every 20 months. Now it's doubling around once every six months.

So all of these graphs show AI development. And then these graphs that we looked at earlier show the unexplained global growth. So is this the explanation then? Is the AI development going to be the cause of this future exponential growth?

One possible perspective is that there's a third element in between them. Let's make a scale of intelligence. We'll assume rocks are dumb and we'll put those on the bottom. Mice are smarter, we'll put them here. We'll put chimps here and humans here. AI is currently less intelligent than a human.

How fast is AI intelligence increasing? It's been around for less than 100 years, and now you can talk to it. How fast is human intelligence increasing? The human brain's capacity for intelligence hasn't changed in over 100,000 years. AIs aren't currently smart enough to create smarter AIs, and humans are. So somewhere between current AI intelligence and human intelligence, there is this threshold, the point at which AI becomes intelligent enough to improve itself.

Unless a meteor strikes Earth and wipes us out soon, AI is going to cross this threshold. All those graphs about AI growth, they show us the forces that are pushing this line up. So the idea is that they push the line up, the line would cross the threshold, AI would become as intelligent as a human, and that crossing of that threshold, that's the cause of the future exponential growth.

So that's what sits in between all those graphs about the development of AI and all those graphs about the future exponential growth. These graphs about AI really only show the human forces: humans pouring money into AI and humans pouring human thoughts into the development of AI. They show the forces created by our current system, so they're not new forces. They're the ones we're used to.

But once those forces push the AI's intelligence up past this threshold, then at that point the AI will start to exert its own forces. Earlier we were looking at these graphs of humanity's future exponential growth and we were trying to understand what the underlying forces were. This would be an example of a new force like that, something new that emerges that influences the world. And as it grows, its effect on the world grows, and it would grow faster than human effects on the world, until eventually the vast majority of activity in the world is this force instead of human forces.

And once this change begins, we have no idea how quickly it will happen. No idea what will happen to us. We don't know how we would maintain control over it after it becomes smarter than us. To me, the idea of us maintaining control over something that's more intelligent than us brings to mind this image of a world where there's all these three-year-olds in the world and they have control over their parents, and they have control over the adults in the government. Or imagine a world where all the chimps have control over all the humans.

Even if we're initially under the impression that we control it, it will continue to grow and develop and gain more capabilities, more power, more infrastructure, be more integrated with systems that humans rely on. It just becomes harder and harder to imagine how the primates would actually stay in control forever and ever.

And how will it treat us? Making sure that the AI isn't mean to us is called the alignment problem, and it's unsolved. If its goals are aligned with our goals, then it'll be nice to us. If its goals are not aligned with our goals, then, you know what, we still had a good run.

When trying to solve alignment, the only problem is it's a real head-scratcher. But you'll figure it out. You got this. Anything is possible if you believe.

If no one is able to solve the alignment problem, then the world will move forward with what appears to be its current plan. Here it is. What you do is you assume that everything's going to be all right. It's a classic plan, tried and true. But in the unlikely event that things don't go according to plan, then having a solution to the alignment problem is probably, well, it's probably too late by that point. But if we try really hard, we could try to get it faster.

Once the AI improves itself to the point where it has surpassed all human capabilities, it's called a superintelligence. Imagine how much variation there could be across all the different possible types of superintelligences. And so there's this vast space of possibilities. We obviously don't know what's in that space, let alone what specific type of superintelligence we will end up with. We also don't know if there will be multiple superintelligences, or if maybe more powerful superintelligences tend to subsume the weaker ones, so there'll really only be one primary superintelligence.

There's so much about superintelligences that we don't understand. It's kind of like when there were dinosaurs and a meteor struck Earth. They didn't even know what meteors were. They didn't know what space was. It just kind of appeared one day and then they burst into fire. Really, there was no way they even could understand it.

Also, if a meteor had struck Earth 100 years ago, we would have been in the same position as the dinosaurs, and there's no reason why that didn't happen other than just random chance. There's no reason why we should survive. The universe is not trying to help us. We're not the main characters. There's nothing that actually protects us. We have to do what we can.

Is there anything that we can predict about the goals of a superintelligence? Imagine my goal was to gather lily pads. If I die, I can't accomplish this goal. No matter what your goals are, staying alive tends to be very useful. We can then predict that by default, the superintelligence will resist any attempts of ours to destroy it, or it will just manipulate us into not wanting to destroy it in the first place. We may be able to switch the superintelligence's default away from that by solving the alignment problem, but that would take a concerted effort. It would take large amounts of money put towards researching and testing and implementing and enforcing and so on.

By default, we can expect the superintelligence to be dangerous. Making AI more powerful makes money, but making AI more safe does not. So currently, large amounts of money are put towards making it more powerful, and hardly anything is put towards making it safe.

Today we're at this critical moment where we can still have an influence over how this goes, but this window is closing.

Also, just like as a PSA, it is possible for us to have a future that's worse than death. I think it's less likely that we'll have one of those futures than just a regular boring death future. But if something like that does happen, it's called an s-risk. If that ever happened, I'd be like, "Aw, doggone it."

If our species is facing something like an extinction, maybe it would be useful for us to try to understand how we were able to avoid extinction in the past, when all the other human-like species died out. The author and historian Yuval Noah Harari has said that one possible reason why we might have survived is our ability to cooperate. Maybe while all the other species were staying in relatively isolated groups, we were communicating with one another, trading, sharing ideas, working together. If cooperation is what makes our species special, maybe this would be a good time to make use of it.

All right, that's the end. Thank you for watching my video. If you want to support me, I have a Patreon. Ideally someday I'd be able to do this kind of thing full-time, but until then I'll still need to pay rent, so that's where you come in. You can hire me to make videos, graphics, media, animations. Lastly, there's this animation I'm almost finished, and I'll upload it to my channel once it's done.

[Music]
