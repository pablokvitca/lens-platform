---
phase: 07-answer-box
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - core/tables.py
  - core/assessments.py
  - core/__init__.py
  - alembic/versions/  # new migration file
  - web_api/routes/assessments.py
  - web_frontend/src/types/module.ts
  - web_frontend/src/api/assessments.ts
  - web_frontend/src/hooks/useAutoSave.ts
  - web_frontend/src/hooks/__tests__/useAutoSave.test.ts
  - web_frontend/src/components/module/AnswerBox.tsx
  - web_frontend/src/views/Module.tsx
autonomous: true

must_haves:
  truths:
    - "Student sees an answer box with question prompt rendered inline within module content"
    - "Student can type a free-text response into the answer box"
    - "Answer text is preserved continuously — no save button needed, no data loss on refresh"
    - "Student can click Finish to mark an answer as complete"
    - "Answers persist across page refresh — student sees their previous text on return"
    - "Save status indicator shows Saving.../Saved feedback"
  artifacts:
    - path: "web_frontend/src/components/module/AnswerBox.tsx"
      provides: "Answer box component with textarea, auto-save, completion flow"
      min_lines: 80
    - path: "web_frontend/src/hooks/__tests__/useAutoSave.test.ts"
      provides: "TDD test suite for useAutoSave hook — 9 test cases covering lazy create, update, debounce, status transitions, load, complete, unmount flush, error recovery"
      min_lines: 150
    - path: "web_frontend/src/hooks/useAutoSave.ts"
      provides: "Debounced auto-save hook with lazy create (POST) then update (PATCH) pattern"
      min_lines: 60
    - path: "web_frontend/src/api/assessments.ts"
      provides: "API client for assessment endpoints (create, update, load responses)"
      min_lines: 40
    - path: "web_api/routes/assessments.py"
      provides: "PATCH /api/assessments/responses/{response_id} endpoint"
      contains: "update_assessment_response"
    - path: "core/assessments.py"
      provides: "update_response function for PATCH operations"
      contains: "update_response"
  key_links:
    - from: "web_frontend/src/components/module/AnswerBox.tsx"
      to: "web_frontend/src/hooks/useAutoSave.ts"
      via: "useAutoSave hook call"
      pattern: "useAutoSave"
    - from: "web_frontend/src/hooks/useAutoSave.ts"
      to: "web_frontend/src/api/assessments.ts"
      via: "createResponse and updateResponse API calls"
      pattern: "createResponse|updateResponse"
    - from: "web_frontend/src/api/assessments.ts"
      to: "/api/assessments/responses"
      via: "fetch calls to backend endpoints"
      pattern: "api/assessments/responses"
    - from: "web_frontend/src/views/Module.tsx"
      to: "web_frontend/src/components/module/AnswerBox.tsx"
      via: "renderSegment case for question type"
      pattern: 'case "question"'
---

<objective>
Build the AnswerBox component with auto-expanding textarea, debounced auto-save via PATCH endpoint, completion flow, and Module.tsx integration so students can type free-text answers that are continuously persisted.

Purpose: This is the core answer input mechanism for the assessment system. Students need to type answers inline within module content, with Google Docs-style auto-save so no work is lost. The useAutoSave hook is the complex logic center — TDD ensures its lazy-create, debounce, status transitions, and error handling are correct before building the UI shell around it.

Output: Working answer box with a TDD-tested useAutoSave hook (9 test cases), rendering for `question` segments, auto-saving text to the database, showing save status, supporting completion, and loading existing answers on revisit.
</objective>

<execution_context>
@/home/penguin/.claude/get-shit-done/workflows/execute-plan.md
@/home/penguin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-answer-box/07-CONTEXT.md
@.planning/phases/07-answer-box/07-RESEARCH.md
@.planning/phases/06-data-foundation/06-01-SUMMARY.md
@.planning/phases/06-data-foundation/06-02-SUMMARY.md

Key source files to reference:
@core/tables.py (assessment_responses table at line 434)
@core/assessments.py (existing CRUD functions)
@web_api/routes/assessments.py (existing POST/GET endpoints)
@web_frontend/src/types/module.ts (ModuleSegment union — needs QuestionSegment)
@web_frontend/src/api/progress.ts (auth header pattern to follow)
@web_frontend/src/views/Module.tsx (renderSegment switch at line 808)
@web_frontend/src/config.ts (API_URL)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Backend — Add completed_at column, update_response function, and PATCH endpoint</name>
  <files>
    core/tables.py
    core/assessments.py
    core/__init__.py
    alembic/versions/ (new migration)
    web_api/routes/assessments.py
  </files>
  <action>
    **1. Add `completed_at` column to assessment_responses table in `core/tables.py`:**
    - Add `Column("completed_at", TIMESTAMP(timezone=True), nullable=True)` to the assessment_responses table definition, after the `created_at` column (before the Indexes comment).
    - This timestamp distinguishes finished answers from in-progress drafts. NULL = in progress, non-NULL = completed.

    **2. Generate Alembic migration:**
    - Run `.venv/bin/alembic revision --autogenerate -m "add completed_at to assessment_responses"`
    - Review the generated migration — it should only contain `add_column` for `completed_at`. Remove any spurious operations (e.g., apscheduler_jobs) as was needed in 06-01.
    - Verify the downgrade properly drops the column.

    **3. Add `update_response` function to `core/assessments.py`:**
    ```python
    async def update_response(
        conn: AsyncConnection,
        *,
        response_id: int,
        user_id: int | None = None,
        anonymous_token: UUID | None = None,
        answer_text: str | None = None,
        answer_metadata: dict | None = None,
        completed_at: str | None = None,  # ISO format string or None
    ) -> dict | None:
    ```
    - Build an UPDATE statement for assessment_responses WHERE response_id = given AND (user_id matches OR anonymous_token matches). This ownership check prevents users from editing others' responses.
    - Only include non-None fields in the SET clause (partial update).
    - If `completed_at` is provided as an ISO string, parse it with `datetime.fromisoformat()`. If provided as empty string or "null", set the column to NULL (for reopening in lesson mode).
    - Use `.returning(assessment_responses)` to return the updated row.
    - Return `dict(row._mapping)` if row found, `None` if no matching row.
    - Follow the same patterns as existing functions (SQLAlchemy Core, async, type hints).

    **4. Export `update_response` from `core/__init__.py`:**
    - Add `update_response` to the imports from `core.assessments`.

    **5. Add PATCH endpoint to `web_api/routes/assessments.py`:**
    - Add `UpdateResponseRequest` Pydantic model:
      ```python
      class UpdateResponseRequest(BaseModel):
          answer_text: str | None = None
          answer_metadata: dict | None = None
          completed_at: str | None = None  # ISO format or empty string to clear
      ```
    - Add PATCH endpoint at `/responses/{response_id}`:
      ```python
      @router.patch("/responses/{response_id}", response_model=SubmitResponseResponse)
      async def update_assessment_response(
          response_id: int,
          body: UpdateResponseRequest,
          auth: tuple = Depends(get_user_or_anonymous),
      ):
      ```
    - Import `update_response` from `core.assessments`.
    - Use `get_transaction()` for the database operation (writes need transactions).
    - Return 404 if `update_response` returns None.
    - Format `created_at` as ISO string (same pattern as existing submit endpoint).

    **6. Update `ResponseItem` model** to include `completed_at: str | None` field, and update `_format_response_items` to include it.

    **7. Relax the POST endpoint's answer_text validation**: Currently `submit_assessment_response` rejects empty `answer_text`. For lazy-create on first keystroke, the initial POST may have very short text. Change validation to allow any non-None text (remove the `.strip()` emptiness check, but keep `.strip()` on the stored value). Actually, better: keep it as-is since the first keystroke will produce at least one character. No change needed here.

    **Run checks:**
    - `ruff check .` and `ruff format --check .` must pass
    - `pytest` must pass (existing tests should still work since we're only adding, not changing existing behavior)
  </action>
  <verify>
    - `ruff check . && ruff format --check .` passes clean
    - `pytest` passes (all existing tests)
    - Migration file exists and contains only `add_column` for `completed_at`
    - `grep -n "update_response" core/assessments.py` shows the new function
    - `grep -n "patch" web_api/routes/assessments.py` shows the new endpoint
    - `grep -n "completed_at" core/tables.py` shows the new column
  </verify>
  <done>
    PATCH /api/assessments/responses/{response_id} endpoint exists and can update answer_text, answer_metadata, and completed_at. The update_response core function performs ownership-checked partial updates. Migration adds completed_at column. ResponseItem includes completed_at in GET responses.
  </done>
</task>

<task type="auto">
  <name>Task 2: TDD — Write useAutoSave hook tests (RED), then implement the hook (GREEN)</name>
  <files>
    web_frontend/src/types/module.ts
    web_frontend/src/api/assessments.ts
    web_frontend/src/hooks/__tests__/useAutoSave.test.ts
    web_frontend/src/hooks/useAutoSave.ts
  </files>
  <action>
    This task follows TDD: write failing tests first, then implement to make them pass.

    **PREREQUISITE — Create supporting types and API client first (needed by both tests and hook):**

    **P1. Add QuestionSegment type to `web_frontend/src/types/module.ts`:**
    ```typescript
    export type QuestionSegment = {
      type: "question";
      userInstruction: string;
      assessmentPrompt?: string;
      maxTime?: string;
      maxChars?: number;
      enforceVoice?: boolean;
      optional?: boolean;
    };
    ```
    - Add `QuestionSegment` to the `ModuleSegment` union type.
    - Also add a `TestSection` type for completeness (Phase 8 will use it, but the content processor already emits type "test"):
    ```typescript
    export type TestSection = {
      type: "test";
      contentId: string | null;
      learningOutcomeId: string | null;
      learningOutcomeName: string | null;
      meta: { title: string | null };
      segments: ModuleSegment[];
      optional: boolean;
    };
    ```
    - Add `TestSection` to the `ModuleSection` union.

    **P2. Create `web_frontend/src/api/assessments.ts`:**
    Follow the pattern from `api/progress.ts` — use `fetchWithRefresh`, `getAnonymousToken`, `API_URL`.

    Functions needed:
    - `createResponse(params)`: POST to `/api/assessments/responses` — creates a new response record. Params: `{ questionId, moduleSlug, learningOutcomeId?, contentId?, answerText, answerMetadata? }`. Returns `{ response_id, created_at }`.
    - `updateResponse(responseId, params)`: PATCH to `/api/assessments/responses/{responseId}` — updates an existing response. Params: `{ answerText?, answerMetadata?, completedAt? }`. Returns `{ response_id, created_at }`.
    - `getResponses(params)`: GET from `/api/assessments/responses` with query params `module_slug` and `question_id`. Returns `{ responses: ResponseItem[] }`.

    Each function should:
    - Accept an `isAuthenticated: boolean` parameter
    - Use `getAuthHeaders(isAuthenticated)` helper (same pattern as progress.ts)
    - Include `credentials: "include"` for cookie-based auth
    - Set `Content-Type: application/json` for POST/PATCH
    - Throw on non-ok response

    **RED PHASE — Write failing tests in `web_frontend/src/hooks/__tests__/useAutoSave.test.ts`:**

    Mock boundary: Mock the `@/api/assessments` module at the top level:
    ```typescript
    import { vi, describe, it, expect, beforeEach, afterEach } from "vitest";
    import { renderHook, act, waitFor } from "@testing-library/react";

    vi.mock("@/api/assessments", () => ({
      createResponse: vi.fn(),
      updateResponse: vi.fn(),
      getResponses: vi.fn(),
    }));

    import { createResponse, updateResponse, getResponses } from "@/api/assessments";
    import { useAutoSave } from "../useAutoSave";
    ```

    Use `vi.useFakeTimers()` in `beforeEach`, `vi.useRealTimers()` in `afterEach`. Reset all mocks in `beforeEach`.

    Default mock setup: `getResponses` resolves to `{ responses: [] }` (no existing answers). `createResponse` resolves to `{ response_id: 42, created_at: "..." }`. `updateResponse` resolves to `{ response_id: 42, created_at: "..." }`.

    Default hook options for all tests:
    ```typescript
    const defaultOpts = {
      questionId: "mod:0:0",
      moduleSlug: "test-module",
      isAuthenticated: false,
      debounceMs: 1000,
    };
    ```

    **Write these 9 test cases (all should FAIL since useAutoSave.ts doesn't exist yet):**

    1. **Lazy create: first setText triggers POST after debounce**
       - `renderHook(() => useAutoSave(defaultOpts))`
       - Wait for loading to finish (getResponses resolves)
       - `act(() => result.current.setText("hello"))`
       - `act(() => vi.advanceTimersByTime(1000))` — advance past debounce
       - Wait for save to complete
       - Assert: `createResponse` called once with `answerText: "hello"` and correct `questionId`, `moduleSlug`
       - Assert: `updateResponse` NOT called
       - Assert: `result.current.responseId` is 42

    2. **Update after create: second setText triggers PATCH**
       - Render, wait for load, setText("hello"), advance timers, wait for create to complete
       - `act(() => result.current.setText("hello world"))`
       - `act(() => vi.advanceTimersByTime(1000))`
       - Wait for save to complete
       - Assert: `updateResponse` called once with `responseId: 42` and `answerText: "hello world"`
       - Assert: `createResponse` called exactly once (from step 1, not again)

    3. **Debounce coalescing: multiple rapid setText calls produce one API call**
       - Render, wait for load
       - `act(() => { result.current.setText("a"); vi.advanceTimersByTime(500); })`
       - `act(() => { result.current.setText("ab"); vi.advanceTimersByTime(500); })`
       - `act(() => { result.current.setText("abc"); vi.advanceTimersByTime(1000); })`
       - Wait for save
       - Assert: `createResponse` called exactly once with `answerText: "abc"` (the latest text)

    4. **Save status transitions: idle -> saving -> saved -> idle**
       - Use a deferred promise for `createResponse` (let it resolve manually to observe intermediate states)
       - Render, wait for load
       - Assert status is `"idle"`
       - setText("test"), advance timers past debounce
       - Assert status becomes `"saving"`
       - Resolve the createResponse promise
       - Assert status becomes `"saved"`
       - Advance timers by 2000ms (saved -> idle transition)
       - Assert status is `"idle"`

    5. **Load existing draft on mount: GET returns incomplete response**
       - Override `getResponses` to return `{ responses: [{ response_id: 99, answer_text: "draft text", completed_at: null }] }`
       - Render hook
       - Wait for load
       - Assert: `result.current.text` is `"draft text"`
       - Assert: `result.current.responseId` is 99
       - Assert: `result.current.isCompleted` is false

    6. **Load completed answer on mount: GET returns response with completed_at**
       - Override `getResponses` to return `{ responses: [{ response_id: 99, answer_text: "done", completed_at: "2025-01-01T00:00:00Z" }] }`
       - Render hook
       - Wait for load
       - Assert: `result.current.isCompleted` is true
       - Assert: `result.current.text` is `"done"`

    7. **markComplete: flushes pending save then PATCHes completed_at**
       - Render, wait for load, setText("answer"), advance timer, wait for create
       - setText("answer v2") — pending change, do NOT advance timer yet
       - `await act(() => result.current.markComplete())`
       - Assert: `updateResponse` was called with `answerText: "answer v2"` (flush) AND then called with `completedAt` set (completion PATCH)
       - Assert: `result.current.isCompleted` is true

    8. **Flush on unmount: pending save fires before cleanup**
       - Render, wait for load, setText("unsaved")
       - Do NOT advance timer (save is pending)
       - `unmount()` the hook
       - Assert: `createResponse` was called with `answerText: "unsaved"`

    9. **Error recovery: API error sets saveStatus to 'error', text preserved**
       - Override `createResponse` to reject with `new Error("network")`
       - Render, wait for load
       - setText("oops"), advance timer, wait for save attempt
       - Assert: `result.current.saveStatus` is `"error"`
       - Assert: `result.current.text` is `"oops"` (not cleared)

    **Run tests — they should all FAIL** (module not found or import error):
    ```bash
    cd web_frontend && npx vitest run src/hooks/__tests__/useAutoSave.test.ts
    ```

    **GREEN PHASE — Implement `web_frontend/src/hooks/useAutoSave.ts` to pass all tests:**

    Interface:
    ```typescript
    interface UseAutoSaveOptions {
      questionId: string;
      moduleSlug: string;
      learningOutcomeId?: string | null;
      contentId?: string | null;
      isAuthenticated: boolean;
      debounceMs?: number; // default 2500
    }

    interface UseAutoSaveReturn {
      text: string;
      setText: (text: string) => void;
      setMetadata: (metadata: Record<string, unknown>) => void;
      saveStatus: 'idle' | 'saving' | 'saved' | 'error';
      isCompleted: boolean;
      markComplete: () => Promise<void>;
      reopenAnswer: () => Promise<void>;
      responseId: number | null;
      isLoading: boolean;
    }
    ```

    Implementation details:
    - **On mount:** Call `getResponses({ moduleSlug, questionId, isAuthenticated })` to load existing answers. Find the most recent response. If it has no `completed_at`, resume editing (set responseId, set text). If all are completed, set `isCompleted` state.
    - **On text change via setText:** Store in state, start debounce timer. If no responseId yet (first keystroke), queue a POST. If responseId exists, queue a PATCH.
    - **Debounce logic:** Use `useRef` for timer. On each setText call, clear existing timer, set new one for `debounceMs`. When timer fires, call `flushSave()`.
    - **flushSave():** The core save function. Uses a `savingRef` to prevent concurrent saves. If `responseId` is null, POST to create (sets responseId from response). If `responseId` exists, PATCH to update. Updates `saveStatus` state.
    - **Save status timing:** Show "Saving..." immediately when save starts. Show "Saved" on success, transition to "idle" after 2 seconds.
    - **On unmount:** `useEffect` cleanup must flush any pending save. Fire-and-forget the pending save call (since the component is unmounting, we can't await).
    - **markComplete():** Flush any pending text save, then PATCH with `completed_at` set to `new Date().toISOString()`. Set `isCompleted` state.
    - **reopenAnswer():** Create a new response via POST (new attempt), reset `isCompleted`, set new responseId.
    - **setMetadata(metadata):** Merges keys into a `metadataRef`. On each save, include metadata as `answer_metadata`.
    - **Race condition prevention:** Use a ref (`latestTextRef`) to always send the latest text. Use a `pendingSaveRef` boolean to queue at most one pending save while a save is in flight.
    - **Error handling:** On save failure, set saveStatus to 'error'. Don't lose the text — keep it in state. The next debounce will retry.

    **Run tests — they should all PASS:**
    ```bash
    cd web_frontend && npx vitest run src/hooks/__tests__/useAutoSave.test.ts
    ```

    Iterate until all 9 tests pass. Do not modify tests to match implementation — fix the implementation to match the tests.
  </action>
  <verify>
    - `cd web_frontend && npx vitest run src/hooks/__tests__/useAutoSave.test.ts` — all 9 tests pass
    - `cd web_frontend && npm run lint` passes clean
    - `cd web_frontend && npm run build` passes clean (TypeScript compiles)
  </verify>
  <done>
    useAutoSave hook is fully tested (9 test cases) and implemented. Tests cover: lazy create (POST on first save), update after create (PATCH), debounce coalescing, save status transitions, loading existing draft, loading completed answer, markComplete with flush, unmount flush, and error recovery. All tests pass. The hook is ready for use by AnswerBox.
  </done>
</task>

<task type="auto">
  <name>Task 3: Frontend — AnswerBox component and Module.tsx integration</name>
  <files>
    web_frontend/src/components/module/AnswerBox.tsx
    web_frontend/src/views/Module.tsx
  </files>
  <action>
    This task uses the tested useAutoSave hook from Task 2 to build the UI shell and integrate it.

    **1. Create `web_frontend/src/components/module/AnswerBox.tsx`:**
    A minimal, inline answer box component.

    Props:
    ```typescript
    interface AnswerBoxProps {
      segment: QuestionSegment;
      moduleSlug: string;
      sectionIndex: number;
      segmentIndex: number;
      learningOutcomeId?: string | null;
      contentId?: string | null;
      isAuthenticated: boolean;
    }
    ```

    Structure:
    - Question prompt: Display `segment.userInstruction` as a paragraph above the textarea. Style with slightly larger/bolder text to distinguish from body text.
    - Auto-expanding textarea: Use the same pattern from NarrativeChatSection (set height to auto, then scrollHeight). But do NOT cap maxHeight — let the textarea grow with content (students write long answers). Add a generous minHeight (e.g., 120px / ~4 lines).
    - Character count: If `segment.maxChars` is set, show `{text.length}/{segment.maxChars}` below the textarea. If over limit, show in red/warning color. Enforce maxLength on the textarea.
    - Save status indicator: Small text below textarea, left-aligned. "Saving..." in muted color, "Saved" with a subtle checkmark, fades away after 2s. "Error saving" in red if error.
    - Finish button: Right-aligned below textarea. Text: "Finish" when active, "Completed" when done. Disabled when text is empty or already completed. Use a subtle style (not primary button — this isn't a heavy action). When clicked, calls `markComplete()`.
    - Completed state: Show the answer text as non-editable (textarea with `disabled` or replace with a styled div). Show a "Completed" badge. In lesson context (not test), show a small "Edit" or "Answer again" link that calls `reopenAnswer()`.
    - Loading state: While `isLoading` is true, show a subtle skeleton or placeholder in the textarea area.
    - Generate questionId deterministically: `${moduleSlug}:${sectionIndex}:${segmentIndex}` — stable as long as content structure doesn't change.

    Styling guidelines (from CONTEXT decisions):
    - Light, inline style — NOT a heavy card. No card shadow, no thick borders.
    - Subtle border on the textarea (e.g., `border-gray-200` or `border-stone-200`).
    - Use the same `max-w-content` wrapper as other content for consistent width.
    - Rounded corners on textarea (`rounded-lg`).
    - Focus ring on textarea (`focus:ring-2 focus:ring-blue-500` or matching site accent).
    - `py-6` vertical spacing to separate from surrounding content.
    - Use Tailwind's `transition-opacity` for save indicator fade.

    **2. Integrate into `web_frontend/src/views/Module.tsx`:**
    - Import `AnswerBox` component.
    - Import `QuestionSegment` type (if needed for type narrowing).
    - Add a `case "question":` to the `renderSegment` switch (after the `case "chat":` block):
      ```tsx
      case "question":
        return (
          <AnswerBox
            key={`question-${keyPrefix}`}
            segment={segment}
            moduleSlug={module.slug}
            sectionIndex={sectionIndex}
            segmentIndex={segmentIndex}
            learningOutcomeId={
              "learningOutcomeId" in section ? section.learningOutcomeId : null
            }
            contentId={"contentId" in section ? section.contentId : null}
            isAuthenticated={isAuthenticated}
          />
        );
      ```
    - The `isAuthenticated` variable already exists in Module.tsx (from `useAuth()`).

    **Run checks:**
    - `cd web_frontend && npm run lint` must pass
    - `cd web_frontend && npm run build` must pass (TypeScript type check + Vite build)
    - `cd web_frontend && npx vitest run src/hooks/__tests__/useAutoSave.test.ts` — still passes (no regressions)
  </action>
  <verify>
    - `cd web_frontend && npm run lint` passes clean
    - `cd web_frontend && npm run build` passes clean
    - `cd web_frontend && npx vitest run src/hooks/__tests__/useAutoSave.test.ts` — all 9 tests still pass
    - `grep -n 'case "question"' web_frontend/src/views/Module.tsx` shows the integration
    - Files exist: `web_frontend/src/components/module/AnswerBox.tsx`
  </verify>
  <done>
    AnswerBox component renders inline for question segments in module content. Auto-expanding textarea accepts free-text input. Uses the tested useAutoSave hook for lazy-create + debounced-update. Save status indicator shows feedback. Finish button marks answer complete. Existing answers load on mount (no data loss on refresh). Module.tsx renders AnswerBox for question segment type.
  </done>
</task>

</tasks>

<verification>
After all three tasks complete:
1. `ruff check . && ruff format --check .` passes (Python)
2. `pytest` passes (all existing + any new tests)
3. `cd web_frontend && npm run lint && npm run build` passes (TypeScript + build)
4. `cd web_frontend && npx vitest run src/hooks/__tests__/useAutoSave.test.ts` — all 9 tests pass
5. PATCH endpoint exists at `/api/assessments/responses/{response_id}`
6. AnswerBox component exists and is wired into Module.tsx renderSegment
7. QuestionSegment type exists in module.ts and is part of ModuleSegment union
8. useAutoSave hook implements lazy-create + debounced-update pattern (verified by tests)
9. API client `assessments.ts` has createResponse, updateResponse, getResponses functions
</verification>

<success_criteria>
- useAutoSave hook has 9 passing test cases covering all critical behaviors
- A question segment in module content renders an answer box with the question prompt
- Typing into the answer box auto-saves after ~2.5s debounce
- The first keystroke creates a new response record (POST), subsequent saves update it (PATCH)
- Save status indicator shows Saving.../Saved feedback
- Clicking Finish marks the answer as complete (sets completed_at)
- Refreshing the page loads the existing answer text
- Character count shows when maxChars is configured
- The answer box has minimal, inline styling that blends with module content
</success_criteria>

<output>
After completion, create `.planning/phases/07-answer-box/07-01-SUMMARY.md`
</output>
