---
phase: 06-data-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - core/tables.py
  - core/assessments.py
  - core/__init__.py
  - alembic/versions/xxxx_add_assessment_tables.py
autonomous: true

must_haves:
  truths:
    - "Assessment response records can be created in the database with user, question reference, module, learning outcome, and answer text"
    - "Assessment score records can be stored as JSONB alongside their parent response"
    - "Anonymous responses can be claimed by authenticated users (same pattern as progress records)"
    - "Multiple responses per user per question are supported (separate records, not upserts)"
  artifacts:
    - path: "core/tables.py"
      provides: "assessment_responses and assessment_scores table definitions"
      contains: "assessment_responses"
    - path: "core/assessments.py"
      provides: "Business logic for creating/querying assessment data"
      exports: ["submit_response", "get_responses", "get_responses_for_question", "claim_assessment_responses"]
    - path: "core/__init__.py"
      provides: "Public exports for assessment functions"
      contains: "assessments"
    - path: "alembic/versions/"
      provides: "Migration to create assessment tables"
      contains: "assessment_responses"
  key_links:
    - from: "core/assessments.py"
      to: "core/tables.py"
      via: "imports assessment_responses, assessment_scores tables"
      pattern: "from .tables import.*assessment"
    - from: "core/assessments.py"
      to: "core/database.py"
      via: "get_connection/get_transaction for DB access"
      pattern: "from .database import"
---

<objective>
Create the database schema and core business logic for assessment data storage.

Purpose: Phases 7-9 all need to store student responses and AI scores. This plan creates the tables and core CRUD functions that everything else builds on.
Output: Two new database tables (assessment_responses, assessment_scores), an Alembic migration, and a core/assessments.py module with submit/query/claim functions.
</objective>

<execution_context>
@/home/penguin/.claude/get-shit-done/workflows/execute-plan.md
@/home/penguin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-data-foundation/06-CONTEXT.md
@.planning/phases/06-data-foundation/06-RESEARCH.md
@core/tables.py
@core/database.py
@core/modules/progress.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add assessment tables to core/tables.py and generate Alembic migration</name>
  <files>core/tables.py, alembic/versions/xxxx_add_assessment_tables.py</files>
  <action>
Add two new table definitions to `core/tables.py`, following the exact patterns used by existing tables (SQLAlchemy Core `Table` objects on the shared `metadata`, same naming convention, same column patterns).

**Table: `assessment_responses`** (section 13):
```python
assessment_responses = Table(
    "assessment_responses",
    metadata,
    Column("response_id", Integer, primary_key=True, autoincrement=True),
    Column("anonymous_token", UUID(as_uuid=True), nullable=True),
    Column("user_id", Integer, ForeignKey("users.user_id", ondelete="CASCADE"), nullable=True),
    Column("question_id", Text, nullable=False),       # Structural ID like "lo-uuid:q1"
    Column("module_slug", Text, nullable=False),
    Column("learning_outcome_id", Text, nullable=True), # LO UUID from content, nullable for inline questions
    Column("content_id", UUID(as_uuid=True), nullable=True),  # Lens/section UUID
    Column("answer_text", Text, nullable=False),
    Column("answer_metadata", JSONB, server_default="{}", nullable=False),  # Voice-used flag, time taken, etc.
    Column("created_at", TIMESTAMP(timezone=True), server_default=func.now()),
    Index("idx_assessment_responses_user_id", "user_id"),
    Index("idx_assessment_responses_anon", "anonymous_token"),
    Index("idx_assessment_responses_question", "question_id"),
    Index("idx_assessment_responses_module", "module_slug"),
)
```

**Table: `assessment_scores`** (section 14):
```python
assessment_scores = Table(
    "assessment_scores",
    metadata,
    Column("score_id", Integer, primary_key=True, autoincrement=True),
    Column("response_id", Integer, ForeignKey("assessment_responses.response_id", ondelete="CASCADE"), nullable=False),
    Column("score_data", JSONB, nullable=False),         # Flexible AI assessment results
    Column("model_id", Text, nullable=True),             # LLM model used
    Column("prompt_version", Text, nullable=True),       # Track rubric/prompt changes
    Column("created_at", TIMESTAMP(timezone=True), server_default=func.now()),
    Index("idx_assessment_scores_response_id", "response_id"),
)
```

Per user decision: JSONB for score_data (schema flexibility). Minimal initial schema — don't over-engineer.

After adding tables, generate the Alembic migration:
```bash
.venv/bin/alembic revision --autogenerate -m "add assessment_responses and assessment_scores tables"
```

Review the generated migration file. Verify it creates both tables with correct columns, indexes, and foreign keys. Fix any issues Alembic gets wrong. Do NOT run the migration yet — that happens after user review.
  </action>
  <verify>
1. `ruff check core/tables.py` passes with no errors
2. The generated migration file exists in `alembic/versions/` and contains CREATE TABLE statements for both `assessment_responses` and `assessment_scores`
3. The migration file has both `upgrade()` and `downgrade()` functions
4. Downgrade drops `assessment_scores` before `assessment_responses` (FK dependency order)
  </verify>
  <done>
Two new table definitions exist in core/tables.py following existing patterns. Alembic migration file generated and reviewed, ready for user approval before running.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create core/assessments.py with CRUD functions and export from core/__init__.py</name>
  <files>core/assessments.py, core/__init__.py</files>
  <action>
Create `core/assessments.py` with business logic functions for assessment data. Follow the pattern from `core/modules/progress.py` — async functions that take a connection, use SQLAlchemy Core queries, and support both `user_id` and `anonymous_token`.

**Functions to implement:**

1. **`submit_response(conn, *, user_id, anonymous_token, question_id, module_slug, learning_outcome_id, content_id, answer_text, answer_metadata) -> dict`**
   - INSERT into assessment_responses, return the created row as dict
   - Exactly one of user_id or anonymous_token must be set (raise ValueError if both None or both set)
   - answer_metadata defaults to empty dict `{}`

2. **`get_responses(conn, *, user_id=None, anonymous_token=None, module_slug=None, question_id=None) -> list[dict]`**
   - SELECT from assessment_responses with optional filters
   - Must filter by user_id OR anonymous_token (at least one required)
   - Optional filters: module_slug, question_id
   - Order by created_at DESC
   - Return list of row dicts

3. **`get_responses_for_question(conn, *, user_id=None, anonymous_token=None, question_id) -> list[dict]`**
   - Convenience wrapper: get all responses for a specific question by the current user
   - Calls get_responses with question_id filter

4. **`claim_assessment_responses(conn, *, anonymous_token, user_id) -> int`**
   - UPDATE assessment_responses SET user_id=X, anonymous_token=NULL WHERE anonymous_token=Y
   - Follow the exact pattern from `claim_progress_records` in `core/modules/progress.py` — skip records where user already has a response for that question_id to avoid issues
   - Return count of claimed records

All functions use `AsyncConnection` type hint from `sqlalchemy.ext.asyncio`. Use `select()`, `insert()`, `update()` from sqlalchemy. Import tables from `core.tables`.

Import style: relative imports within core (e.g., `from .tables import assessment_responses, assessment_scores`, `from .database import get_connection`).

**Export from core/__init__.py:**
Add imports for the public functions:
```python
from .assessments import submit_response, get_responses, get_responses_for_question, claim_assessment_responses
```
  </action>
  <verify>
1. `ruff check core/assessments.py` passes
2. `ruff check core/__init__.py` passes
3. `python -c "from core.assessments import submit_response, get_responses, get_responses_for_question, claim_assessment_responses; print('OK')"` succeeds
  </verify>
  <done>
core/assessments.py exists with submit_response, get_responses, get_responses_for_question, and claim_assessment_responses functions. All exported from core/__init__.py. Functions follow existing codebase patterns (async, SQLAlchemy Core, dual user_id/anonymous_token support).
  </done>
</task>

</tasks>

<verification>
1. `ruff check core/tables.py core/assessments.py core/__init__.py` — all pass
2. Alembic migration file exists and has valid upgrade/downgrade
3. All four functions importable from `core.assessments`
4. Table definitions match the schema from research (JSONB for score_data, dual auth support, proper indexes)
5. No imports from discord_bot/ or web_api/ in core/assessments.py (layer separation)
</verification>

<success_criteria>
- assessment_responses table defined with: response_id, anonymous_token, user_id, question_id, module_slug, learning_outcome_id, content_id, answer_text, answer_metadata (JSONB), created_at
- assessment_scores table defined with: score_id, response_id (FK), score_data (JSONB), model_id, prompt_version, created_at
- Alembic migration generated and reviewed (not yet run)
- core/assessments.py has submit_response, get_responses, get_responses_for_question, claim_assessment_responses
- Functions exported from core/__init__.py
- All linting passes
</success_criteria>

<output>
After completion, create `.planning/phases/06-data-foundation/06-01-SUMMARY.md`
</output>
