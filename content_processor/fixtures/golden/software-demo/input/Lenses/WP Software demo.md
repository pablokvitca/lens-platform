---
id: b2c3d4e5-f6a7-8901-bcde-f23456789012
---
### Article: Understanding Existential Risk from AI
source:: [[../articles/wikipedia-existential-risk-from-ai]]

#### Text
content::
# Understanding Existential Risk from AI

Now let's read an overview of the main concepts regarding AI as a source
of existential threat: what capabilities of this technology are considered
most concerning, and why the task of eliminating AI risks differs from
similar tasks for other technologies.

#### Article-excerpt
from:: "**Existential risk from artificial intelligence**"
to:: "improve their fundamental architecture."

#### Text
content::
**Key concepts so far:**

- AI x-risk refers to the possibility that AGI could cause human extinction
- The "Gorilla Problem": just as gorillas depend on human goodwill, humans
  might depend on AI's goodwill
- Many leading AI researchers take this risk seriously

#### Chat
hidePreviousContentFromUser:: false
hidePreviousContentFromTutor:: false
instructions::
The user just read the introduction to AI existential risk from Wikipedia.

Key concepts covered:
- AI x-risk hypothesis
- The gorilla analogy (Stuart Russell)
- Expert surveys showing concern
- The alignment problem

Discussion topics:
- What is the "Gorilla Problem" and why is it a useful analogy?
- Why do many AI researchers believe there's a significant chance of catastrophe?
- What are the two main sources of concern (control and alignment)?

Ask what they found surprising or new. Check if they can explain the gorilla
analogy in their own wordsâ€”it's a key concept.

#### Article-excerpt
from:: "One of the earliest authors"
to:: "strong public buy-in."

#### Text
content::
This history shows that concerns about AI risk aren't new - thinkers from
Alan Turing to Stephen Hawking have considered these questions.

#### Article-excerpt
from:: "### General Intelligence"
to:: "evasion of human control"

#### Text
content::
Please have a chat with the AI Tutor about the article you just read:

#### Chat
hidePreviousContentFromUser:: false
hidePreviousContentFromTutor:: false
instructions::
The user just read about AGI and superintelligence capabilities.

Key points:
- AGI = human-level across most tasks
- Superintelligence = vastly exceeds humans in all domains
- AI advantages: speed, scalability, duplicability, editability
- Timelines are uncertain but potentially soon

Discussion topics:
- Why might the transition from AGI to superintelligence be rapid?
- Which of the AI advantages over human brains seems most significant?
- How does duplicability change the dynamics of AI development?

Help them understand why these technical properties have such large implications.
