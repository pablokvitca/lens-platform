[
  {
    "text": "Henry: \"Will Artificial Intelligence ever replace humans?\" is a hotly debated question",
    "start": "0:01.41"
  },
  {
    "text": "these days.",
    "start": "0:05.53"
  },
  {
    "text": "Some people claim computers will eventually gain superintelligence, be able to outperform",
    "start": "0:06.53"
  },
  {
    "text": "humans on any task, and destroy humanity.",
    "start": "0:10.10"
  },
  {
    "text": "Other people say \"don't worry, AI will just be another tool we can use and control,",
    "start": "0:12.90"
  },
  {
    "text": "like our current computers.\"",
    "start": "0:16.30"
  },
  {
    "text": "So we've got physicist and AI researcher Max Tegmark back again to share with us the",
    "start": "0:17.60"
  },
  {
    "text": "collective takeaways from the recent Asilomar conference on the future of AI that he helped",
    "start": "0:21.62"
  },
  {
    "text": "organize. He's going to help separate AI myths from AI facts.",
    "start": "0:25.54"
  },
  {
    "text": "Max: Hello!",
    "start": "0:29.17"
  },
  {
    "text": "Henry: First of all, Max, machines (including computers) have long been better than us at",
    "start": "0:30.17"
  },
  {
    "text": "many tasks, like arithmetic or weaving, but those are often repetitive and mechanical",
    "start": "0:34.05"
  },
  {
    "text": "operations.",
    "start": "0:38.17"
  },
  {
    "text": "So why shouldn't I believe that there are some things that are simply impossible for",
    "start": "0:39.17"
  },
  {
    "text": "machines to do as well as people?",
    "start": "0:42.24"
  },
  {
    "text": "Say, making Minutephysics videos or consoling a friend?",
    "start": "0:43.94"
  },
  {
    "text": "Max: Well, we've traditionally thought of intelligence as something mysterious that",
    "start": "0:46.51"
  },
  {
    "text": "can only exist in biological organisms, especially humans.",
    "start": "0:50.15"
  },
  {
    "text": "But from the perspective of modern physical science, intelligence is simply a particular",
    "start": "0:53.37"
  },
  {
    "text": "kind of information processing and reacting performed by particular arrangements of elementary",
    "start": "0:57.28"
  },
  {
    "text": "particles moving around. And there's no law of physics that says it's impossible",
    "start": "1:01.61"
  },
  {
    "text": "to do that kind of information processing better than humans already do.",
    "start": "1:05.24"
  },
  {
    "text": "It's not a stretch to say that earthworms process information better than rocks, and",
    "start": "1:08.47"
  },
  {
    "text": "humans better than earthworms. In many areas, machines are already better than humans.",
    "start": "1:12.36"
  },
  {
    "text": "This suggests we've likely only seen the tip of the intelligence iceberg, and that",
    "start": "1:16.30"
  },
  {
    "text": "we're on track to unlock the full intelligence that's latent in nature and use it to help",
    "start": "1:19.88"
  },
  {
    "text": "humanity flourish\u2014or flounder.",
    "start": "1:24.01"
  },
  {
    "text": "Henry: So how do we keep ourselves on the right side of the \"flourish or flounder\"",
    "start": "1:26.19"
  },
  {
    "text": "balance?",
    "start": "1:30.46"
  },
  {
    "text": "What, if anything, should we really be concerned about with superintelligent AI?",
    "start": "1:31.46"
  },
  {
    "text": "Max: Here's what has many top AI researchers concerned: not machines or computers turning",
    "start": "1:34.54"
  },
  {
    "text": "evil, but something more subtle\u2014superintelligence that simply doesn't share our goals.",
    "start": "1:39.38"
  },
  {
    "text": "If a heat-seeking missile is homing in on you, you probably wouldn't think, \"No",
    "start": "1:43.59"
  },
  {
    "text": "need to worry, it's not evil, it's just following its programming.\"",
    "start": "1:47.42"
  },
  {
    "text": "No, what matters to you is what the heat-seeking missile does and how well it does it, not",
    "start": "1:50.30"
  },
  {
    "text": "what it's feeling or whether it has feelings at all.",
    "start": "1:55.45"
  },
  {
    "text": "The real worry isn't malevolence, but competence.",
    "start": "1:57.59"
  },
  {
    "text": "A superintelligent AI is by definition very good at attaining its goals. So the most important",
    "start": "2:00.86"
  },
  {
    "text": "thing for us to do is ensure that its goals are aligned with ours.",
    "start": "2:05.52"
  },
  {
    "text": "As an analogy, humans are more intelligent and competent than ants. If we want",
    "start": "2:09.06"
  },
  {
    "text": "to build a hydroelectric dam where there happens to be an anthill, there may be no malevolence",
    "start": "2:13.33"
  },
  {
    "text": "involved, but well\u2014too bad for the ants.",
    "start": "2:17.17"
  },
  {
    "text": "Cats and dogs, on the other hand, have done a great job of aligning their goals with the",
    "start": "2:20.00"
  },
  {
    "text": "goals of humans. I mean, even though I'm a physicist, I can't help but think kittens",
    "start": "2:23.75"
  },
  {
    "text": "are the cutest particle arrangements in our universe.",
    "start": "2:28.01"
  },
  {
    "text": "If we build superintelligence, we'd be better off in the position of cats and dogs than",
    "start": "2:31.11"
  },
  {
    "text": "ants.",
    "start": "2:35.07"
  },
  {
    "text": "Or better yet, we'll figure out how to ensure that AI adopts our goals rather than the other",
    "start": "2:36.07"
  },
  {
    "text": "way around.",
    "start": "2:40.06"
  },
  {
    "text": "Henry: And when exactly is superintelligence going to arrive?",
    "start": "2:41.06"
  },
  {
    "text": "When do we need to start panicking?",
    "start": "2:43.93"
  },
  {
    "text": "Max: First of all, Henry, superintelligence doesn't have to be something negative.",
    "start": "2:45.27"
  },
  {
    "text": "In fact, if we get it right, AI might become the best thing ever to happen to humanity.",
    "start": "2:48.70"
  },
  {
    "text": "Everything I love about civilization is the product of intelligence. So if AI amplifies",
    "start": "2:53.03"
  },
  {
    "text": "our collective intelligence enough to solve today's and tomorrow's greatest problems,",
    "start": "2:57.74"
  },
  {
    "text": "humanity might flourish like never before.",
    "start": "3:01.69"
  },
  {
    "text": "Second, most AI researchers think superintelligence is at least decades away.",
    "start": "3:04.02"
  },
  {
    "text": "But the research needed to ensure that it remains beneficial to humanity (rather",
    "start": "3:08.77"
  },
  {
    "text": "than harmful) might also take decades, so we need to start right away.",
    "start": "3:11.95"
  },
  {
    "text": "For example, we'll need to figure out how to ensure machines learn the collective goals",
    "start": "3:16.27"
  },
  {
    "text": "of humanity, adopt these goals for themselves, and retain the goals as they keep getting",
    "start": "3:19.71"
  },
  {
    "text": "smarter.",
    "start": "3:24.28"
  },
  {
    "text": "And what about when our goals disagree?",
    "start": "3:25.28"
  },
  {
    "text": "Should we vote on what the machine's goals should be?",
    "start": "3:26.59"
  },
  {
    "text": "Just do whatever the president wants?",
    "start": "3:28.96"
  },
  {
    "text": "Whatever the creator of the superintelligence wants?",
    "start": "3:31.30"
  },
  {
    "text": "Let the AI decide?",
    "start": "3:33.61"
  },
  {
    "text": "In a very real way, the question of how to live with superintelligence is a question",
    "start": "3:34.76"
  },
  {
    "text": "of what sort of future we want to create for humanity.",
    "start": "3:38.87"
  },
  {
    "text": "Which obviously shouldn't just be left to AI researchers, as caring and socially skilled",
    "start": "3:41.65"
  },
  {
    "text": "as we are.",
    "start": "3:46.06"
  },
  {
    "text": "Henry: Thanks, Max!",
    "start": "3:47.06"
  },
  {
    "text": "So, uh, how do I get involved to make sure we don't end up living in a superintelligence-powered",
    "start": "3:48.06"
  },
  {
    "text": "dictatorship?",
    "start": "3:52.50"
  },
  {
    "text": "Max: At the Future of Life Institute (Henry interjects: which is sponsoring this video),",
    "start": "3:53.50"
  },
  {
    "text": "we've built a site where you can go to answer questions, ask questions, and otherwise contribute",
    "start": "3:55.97"
  },
  {
    "text": "your thoughts to help shape the future of AI policy and research.",
    "start": "4:00.28"
  },
  {
    "text": "The link's in the video description.",
    "start": "4:03.16"
  },
  {
    "text": "Henry: Awesome.",
    "start": "4:05.58"
  }
]