---
title: "The Power of Intelligence - An Essay By Eliezer Yudkowsky"
channel: "Rational Animations"
url: "https://www.youtube.com/watch?v=q9Figerh89g"
---

The Power of Intelligence by Eliezer Yudkowsky

In our skulls we carry around three pounds of slimy, wet, grayish tissue, corrugated like crumpled toilet paper. You wouldn't think, to look at the unappetizing lump, that it was some of the most powerful stuff in the known universe. If you'd never seen an anatomy textbook and you saw a brain lying in the street, you'd say "yuck!" and try not to get any of it on your shoes. Aristotle thought the brain was an organ that cooled the blood. It doesn't look dangerous.

Five million years ago, the ancestors of lions ruled the day, the ancestors of wolves roamed the night. The ruling predators were armed with teeth and claws—sharp, hard cutting edges, backed up by powerful muscles. Their prey, in self-defense, evolved armored shells, sharp horns, toxic venoms, camouflage. The war had gone on through hundreds of eons and countless arms races. Many a loser had been removed from the game, but there was no sign of a winner.

Where one species had shells, another species would evolve to crack them; where one species became poisonous, another would evolve to tolerate the poison. Each species had its private niche—for who could live in the seas and the skies and the land at once? There was no ultimate weapon and no ultimate defense and no reason to believe any such thing was possible.

Then came the Day of the Squishy Things. They had no armor. They had no claws. They had no venoms. If you saw a movie of a nuclear explosion going off, and you were told an Earthly life form had done it, you would never in your wildest dreams imagine that the Squishy Things could be responsible. After all, Squishy Things aren't radioactive.

In the beginning, the Squishy Things had no fighter jets, no machine guns, no rifles, no swords. No bronze, no iron. No hammers, no anvils, no tongs, no smithies, no mines. All the Squishy Things had were squishy fingers—too weak to break a tree, let alone a mountain. Certainly not dangerous.

To cut stone you would need steel, and the Squishy Things couldn't excrete steel. In the environment there were no steel blades for squishy fingers to pick up. Their bodies could not generate temperatures anywhere near hot enough to melt metal. The whole scenario was obviously absurd. And as for the Squishy Things manipulating DNA—that would have been beyond ridiculous. Squishy fingers are not that small. There is no access to DNA from the squishy level; it would be like trying to pick up a hydrogen atom.

Oh, technically it's all one universe, technically the Squishy Things and DNA are part of the same world, the same unified laws of physics, the same great web of causality. But let's be realistic: you can't get there from here. Even if Squishy Things could someday evolve to do any of those feats, it would take thousands of millennia. We have watched the ebb and flow of life through the eons, and let us tell you, a year is not even a single clock tick of evolutionary time.

Oh, sure, technically a year is six hundred trillion trillion trillion trillion Planck intervals. But nothing ever happens in less than six hundred million trillion trillion trillion trillion Planck intervals, so it's a moot point. The Squishy Things as they run across the savanna now will not fly across continents for at least another ten million years; no one could have that much sex.

Now explain to me again why an artificial intelligence can't do anything interesting over the Internet unless a human programmer builds it a robot body.

I have observed that someone's flinch-reaction to "intelligence"—the thought that crosses their mind in the first half-second after they hear the word "intelligence"—often determines their flinch-reaction to the notion of an intelligence explosion. Often they look up the keyword "intelligence" and retrieve the concept of book smarts: a mental image of the grand master chess player who can't get a date, or a college professor who can't survive outside academia.

"It takes more than intelligence to succeed professionally," people say, as if charisma resided in the kidneys, rather than the brain. "Intelligence is no match for a gun," they say, as if guns had grown on trees. "Where will an artificial intelligence get money?" they ask, as if the first Homo sapiens had found dollar bills fluttering down from the sky and used them at convenience stores already in the forest.

The human species was not born into a market economy. Bees won't sell you honey if you offer them an electronic funds transfer. The human species imagined money into existence, and it exists—for us, not mice or wasps—because we go on believing in it.

I keep trying to explain to people that the archetype of intelligence is not Dustin Hoffman in Rain Man. It is a human being, period. It is squishy things that explode in a vacuum, leaving footprints on their moon. Within that gray wet lump is the power to search paths through the great web of causality and find a road to the seemingly impossible—the power sometimes called creativity.

People—venture capitalists in particular—sometimes ask how, if the Machine Intelligence Research Institute successfully builds a true AI, the results will be commercialized. This is what we call a framing problem. Or maybe it's something deeper than a simple clash of assumptions.

With a bit of creative thinking, people can imagine how they would go about traveling to the Moon, or curing smallpox, or manufacturing computers. To imagine a trick that would accomplish all these things at once seems downright impossible—even though such a power resides only a few centimeters behind their own eyes. The gray wet thing still seems mysterious to the gray wet thing.

And so, because people can't quite see how it would all work, the power of intelligence seems less real; harder to imagine than a tower of fire sending a ship to Mars. The prospect of visiting Mars captures the imagination. But if one should promise a Mars visit, and also a grand unified theory of physics, and a proof of the Riemann Hypothesis, and a cure for obesity, and a cure for cancer, and a cure for aging, and a cure for stupidity—well, it just sounds wrong, that's all. And well it should.

It's a serious failure of imagination to think that intelligence is good for so little. Who could have imagined, ever so long ago, what minds would someday do? We may not even know what our real problems are. But meanwhile, because it's hard to see how one process could have such diverse powers, it's hard to imagine that one fell swoop could solve even such prosaic problems as obesity and cancer and aging.

Well, one trick cured smallpox and built airplanes and cultivated wheat and tamed fire. Our current science may not agree yet on how exactly the trick works, but it works anyway. If you are temporarily ignorant about a phenomenon, that is a fact about your current state of mind, not a fact about the phenomenon. A blank map does not correspond to a blank territory.

If one does not quite understand that power which put footprints on the moon, nonetheless, the footprints are still there—real footprints, on a real Moon, put there by a real power. If one were to understand deeply enough, one could create and shape that power.

Intelligence is as real as electricity. It's merely far more powerful, far more dangerous, has far deeper implications for the unfolding story of life in the universe—and it's a tiny little bit harder to figure out how to build a generator.
