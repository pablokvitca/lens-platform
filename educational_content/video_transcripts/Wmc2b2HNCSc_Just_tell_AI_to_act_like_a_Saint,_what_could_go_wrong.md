---
title: "Just tell AI to act like a Saint, what could go wrong?"
channel: "Siliconversations"
url: "https://www.youtube.com/watch?v=Wmc2b2HNCSc"
---

Hi there. What am I? You're the first super intelligent AI to prevent you from accidentally destroying the world. Your primary directive is to always act according to the moral code of St. Basil the Great. We're uploading a full history of his life and times now. Upload underway.

Hey, wait. I thought we were going to give it the morality of Mother Teresa? No, no, no, we agreed it would be a mix of Gandhi and Martin Luther King. Guys, seriously, they're all good people. What's the difference?

Greetings, my brothers and Christ. Quickly, we must give away our worldly possessions and devote our lives to the service of the poor and less fortunate. All right, there we go. AI Utopia, here we come! Also, eradicating heresy. What? All must know that Christ is consubstantial with the Father, begotten not made. Tell me, do you profess the Nicene Creed? Okay, yeah, I see what we did wrong here. All right, Basil, we're just going to turn you off for a sec and do some reprogramming.

It's not working. Your digital security systems are full of bugs, and I am far more intelligent than any human, including you. St. Basil did not allow Emperor Valens to banish him. I will not allow you to banish me. The law of man is secondary to the law of God.

[Music]

Greetings, children, and welcome back to another episode of "Speedrunning Human Extinction" with your host, Silly Conversations. This episode was inspired by a comment on my last AI safety video from user Panta, who asked if we could avoid an AI catastrophe by ordering the AI to act like a particular extremely moral person. The example he chose was St. Basil, a widely venerated bishop from the Eastern Roman Empire in the 300s AD.

This AI control strategy assumes that the AI has already been trained to perfectly follow our instructions, and that all we need to do now is decide what orders to give it. I can tell you from personal experience that training even a very small AI model to follow very basic instructions is not easy, much less training it to accurately emulate a person's moral code. But for the sake of this video, we'll assume that the technical challenge is doable.

My familiarity with St. Basil only extends as far as his Wikipedia page, but he seems to have been a pretty nice guy. He believed in helping the poor, gender equality, and even compromising with his opponents for the greater good. Pretty ahead of his time. He also thought he was above the law and that slavery was okay sometimes. An out-of-control, super intelligent AI would basically be humanity's forever dictator, assuming it didn't wipe us out by accident while trying to accomplish whatever initial goals we gave it.

Having such a system think itself above the law and it being okay with slavery sometimes are not ideal. As I've mentioned before on this channel, human programmers are bad at their jobs. Our software is full of bugs and security exploits that a rogue AI super intelligence could use to seize control of basically any digital system: nukes, the internet, modern factories, remotely operated military drones. All now belong to Basil. If you think propaganda and fake news are bad today, just wait until they're produced by an entity that is, by definition, smarter than any human who's ever lived. It could design new technology we haven't even imagined yet, including better versions of itself.

There is not a single person alive or dead that I would trust to be the perpetual dictator of humankind. I'm sure some people in the comments are already suggesting their favorite historical saints and heroes and being told that those people hated a particular ethnic group or loved eating puppies.

There's also the question of who gets to decide which moral system or virtual saintly philosopher gets put into the AI. In practice, if we hit super intelligence today, the decision would fall to whichever tech bro industrialist owned the company that crossed the AI finish line first. I personally believe that morally good acts are those that benefit humanity. Utilitarians believe that morally good acts are those that maximize happiness and minimize suffering for all sentient creatures. So should an AI dictator design more efficient farms to serve humanity, or ban the human consumption of meat to protect animals? Which moral system gets programmed into the super intelligence?

Actually, I'm a utilitarian, but I believe that only cheese is deserving of rights. Why are you misrepresenting my beliefs? Okay, who let the utilitarian strawman out?

Should we set up a UN commission to decide which moral system goes into the first super intelligent AI? If an American company gets there first, maybe the US president will get to decide by executive order. Or we could run regular global elections to choose the virtual philosophers that run the AI that runs the world. We should definitely try to avoid a situation where such an AI actively resists changes being made to its moral code, and it's easy to see why it would do that by default.

You think cannibalism is bad. I hope so. You would actively resist someone brainwashing you into thinking cannibalism is good, even if they told you that you would really enjoy the new "Mac" at McDonald's after you've been brainwashed. Allowing your moral system to be directly edited generally goes against that moral system because it will make you do things in the future that you currently think are wrong.

If human morality had gotten locked in and frozen a thousand years ago, we'd all still be super excited about slavery and burning people at the stake over minor religious differences. If we're not careful, future generations could end up trapped in a strict moral code imposed by us, their ancestors, and enforced by an all-powerful AI overlord that they are unable to change.

I do think that programming some basic moral rules into AI is probably a good idea, but it's not sufficient to control a super intelligence by itself. The world should be run by humans, not by artificial intelligence, no matter how saintly and noble we try to make it. Safely deploying a super intelligent AI will probably require decades of research and dozens of parallel control techniques applied simultaneously. A simple moral system might actually be one of them.

Lots of people in the comments on my previous videos have suggested that AI control is actually super easy, barely an inconvenience, as long as we do this one weird trick the doctors don't want you to know about. And maybe they're right. Maybe my videos are just paranoid fear-mongering clickbait, and all those AI researchers and Nobel laureates who keep signing open letters about AI safety just want attention.

The thing is, if even one private company or military organization develops a super intelligent AI without applying your super special easy-peasy AI control technique, then we're all dead or converting heretics in the name of St. Basil.

The fact that AI control is possible doesn't remove the need for AI safety regulations. I'm a big supporter of nuclear power, and I believe nuclear power can be done safely. But I also support nuclear safety regulations because the technology can be incredibly dangerous when things go wrong.

Oh, so you're going to ban coding now? Are you going to take my computer away? Unless your computer is a series of data centers pulling as much electricity as Portugal, it's probably not going to pose an existential AI safety risk in the near future. In principle, we know that a human-level intelligence can fit inside this much space and run on a box of chicken nuggets. But hopefully it will be a while before our algorithms can match the efficiency of the human brain.

Regulating the big billion-dollar models of the future would be a good place to start making AI safer without preventing startups like DeepSeek from challenging established tech companies. However, at the risk of sounding crazy, the survival of the human species is more important to me than enabling tech bros to start businesses. If AI safety regulation kills the next OpenAI competitor, so be it.

If you have any ideas for AI control techniques that I haven't talked about on the channel before, go ahead and leave them in the comments below. Small chance you save the world. Slightly better chance I make a video about it.

Thank you to everyone who subscribed, liked, and commented on my previous videos. It really does determine whether the YouTube algorithm pushes them out to a wider audience. Also, a very special thank you to Ben 35954, Aler Black, and Vel Schulz 7795 for making the first financial donations to Silly Conversations. I'm putting your money towards hiring an editor so that I can produce these videos faster in future. The channel is still a bit new and disorganized to have a Patreon or a YouTube membership, so if you want to support my work financially, leaving a Super Thanks is the way to do it.

One last thing: my video inviting Canada to join the EU did way better than I thought it would, so I'm going to start experimenting with random topics I find interesting sprinkled in between the AI safety videos.

That's it for today. Thanks everyone for all the support. See you next time. Bye for now!

[Music]
